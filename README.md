# ğŸ“Œ SLAM Review and Benchmarking
**A repository for SLAM algorithm benchmarking in GPS-denied environments.**

This repository contains **benchmarking codes and evaluation results** for various SLAM algorithms tested under **GPS-denied and enclosed environments (EGD)**. The study investigates **vision-based, LiDAR-based, and LiDAR-vision fusion methods** for robotic infrastructure inspection.

---

## ğŸ’‘ Publication
- ğŸ“ **Title:** A Review of Simultaneous Localization and Mapping for the Robotic-Based Nondestructive Evaluation of Infrastructures
- ğŸ“š **Journal:** Sensors
- ğŸ”— **[Read the Full Paper](https://www.mdpi.com/1424-8220/25/3/712)**

---

## ğŸ“‚ Repository Structure
```
â”œâ”€â”€ benchmark_scripts/    # Code for SLAM evaluation
â”‚   â”œâ”€â”€ vins_mono.py
â”‚   â”œâ”€â”€ orb_slam2.py
â”‚   â”œâ”€â”€ lio_sam.py
â”‚   â”œâ”€â”€ fast_lio2.py
â”‚   â”œâ”€â”€ aloam.py
â”‚   â”œâ”€â”€ final.py
â”‚
â”œâ”€â”€ datasets/             # Dataset files used for benchmarking
â”‚   â”œâ”€â”€ mine_dataset/
â”‚
â”œâ”€â”€ results/              # Benchmarking results & visualizations
â”‚   â”œâ”€â”€ cpu_usage.png
â”‚   â”œâ”€â”€ ground_truth_trajectory.png
â”‚   â”œâ”€â”€ aft_mapped_path.csv
â”‚
â”œâ”€â”€ docs/                 # Documentation
â”‚   â”œâ”€â”€ methodology.md
â”‚   â”œâ”€â”€ SLAM_algorithms_review.md
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md             # Overview of the repository
```

---

<h3 style="color:blue;">ğŸ”¹ SLAM Algorithms Evaluated</h3>

This study benchmarks the following **SLAM methods**:

| **Algorithm**  | **Type** | **Sensor Modality** |
|---------------|----------|--------------------|
| ORB-SLAM2     | Visual   | Monocular, Stereo, RGB-D |
| VINS-Mono     | Visual   | Monocular Camera IMU  |
| LIO-SAM       | LiDAR    | LiDAR + IMU       |
| Fast-LIO2     | LiDAR    | LiDAR + IMU       |
| A-LOAM        | LiDAR    | LiDAR + IMU       |
| LVI-SAM       | Fusion   | LiDAR + Camera + IMU |
| LINS          | LiDAR    | LiDAR + IMU       |
| LEGO-LOAM     | LiDAR    | LiDAR + IMU |
| SC-LEGO-LOAM  | LiDAR    | LiDAR + IMU |
| SC-FAST-LIO   | LiDAR    | LiDAR + IMU |
| F-LOAM        | LiDAR    | LiDAR + IMU |

---

## ğŸ“Š Results

<h3 style="color:green;">ğŸ“Œ Trajectory Error Comparison</h3>
The results include:
- **Accuracy Comparisons:** RMSE plots showing SLAM accuracy
- **Computational Resource Consumption:** Memory and CPU usage and runtime benchmarks
- **Visualizations:** 3D trajectory plots

### **Example Visualizations**
<p><span style="font-size:18px; font-weight:bold;">ğŸ”¹ Accuracy Comparison:</span></p>

<div align="center">
<img src="results/lidar-accuracy.png" alt="LiDAR-based accuracy" width="400">
<img src="results/vision-accuracy.png" alt="Vision-based accuracy" width="400">
<img src="results/trans-err.png" alt="trans-err" width="400">
</div>


<p><span style="font-size:18px; font-weight:bold;">ğŸ”¹ Dataset Collection Device:</span></p>

<div align="center">
<img src="datasets/device.png" alt="Accuracy Plot" width="400">
</div>


ğŸ“Œ **More detailed results can be found in the results section of the corresponding paper.**

---

## ğŸš€ How to Use This Repository
Since this repository **only contains benchmarking codes**, there are no installation steps required. However, to **reproduce the benchmarking results**, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/ali-qdmz/A-Review-of-SLAM-and-Benchmarking.git
   cd A-Review-of-SLAM-and-Benchmarking
   ```
2. Run the relevant SLAM benchmarking script:
   ```bash
   python benchmark_scripts/orb_slam2.py
   ```

## ğŸ“© Contact
For any questions or collaboration opportunities, feel free to reach out:

ğŸ‘¤ **Ali Ghadimzadeh Alamdari**  
ğŸ“§ **[ali.ghadimzadeh@gmail.com]**  
ğŸ”— **[[LinkedIn](https://www.linkedin.com/in/ali-ghadimzadeh-38b12217a/)]**  

---
